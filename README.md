# Enhancing Tiny Object Detection by apply GOIS on Latest YOLO Models and RT-DETR Transformer, The innovative framework proved its significance both for Fine-Tuned and Not Fined-Tuned Models->BY MUZAMMUL(ZJU)
*(Tiny Object Dectection-Benchmarks-Full-Image Detection for Inference  Vs Innovative Framework Guided Object Inference Slicing(GOIS) detection results)
 [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](Guided_Object_Inference_Slicing_Prediction_Vs_Full_Image_Prediction_Evaluation.ipynb)

## Testing Code Steps

### 1. **Download Required Files**
- **Ground Truth (GT)**: Download the COCO.json file containing the ground truth annotations.
- **FI-Det COCO.json**: Download the Full Inference Detection results in COCO.json format.
- **OGIS-Det COCO.json**: Download the Object Guided Inference Slicing Detection results in COCO.json format.
- Upload the files to your preferred storage location (e.g., Google Drive).
- Follow step 6,7 in [https://github.com/MMUZAMMUL/GOIS]
# Section 1: Without Fine Tuning 15% Dataset Subset(970 Images) Inference Results VisDrone2019Train Dataset

## Comparative Results for FI-Det and GOIS-Det
This table presents the Average Precision (AP) and Average Recall (AR) metrics for seven models. Each model includes rows for FI-Det, GOIS-Det, and the percentage improvement achieved by GOIS over FI-Det. Downloadable links for FI-Det and GOIS-Det results are included.Ground Truth COCO for this evaluation available at | [15%TraineDatasetGT]https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/blob/main/Ground_Trouth-COCO.json

| **Model**                                                                                      | **mAP-Small** | **AR-Small** | **mAP-Medium** | **mAP-Large** | **AR@1** | **AR@10** | **AR@100** | **AR-Medium** | **AR-Large** | **F1 Score** | **mAP@0.50:0.95** | **mAP@0.50** | **mAP@0.75** |
|------------------------------------------------------------------------------------------------|---------------|--------------|----------------|---------------|----------|-----------|------------|---------------|--------------|--------------|-------------------|--------------|--------------|
| YOLO11 [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/yolo11/FI_yolo11n.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-YOLO11/GOIS_yolo11n.json) | 0.02 / 0.10    | 0.04 / 0.33  | 0.23 / 0.57    | 0.57 / 0.96    | 0.12 / 0.27 | 0.27 / 0.68   | 0.29 / 0.87   | 0.49 / 1.40     | 1.09 / 1.93     | 0.17 / 0.47  | 0.12 / 0.33        | 0.18 / 0.51   | 0.13 / 0.34   |
|                                                                                               | **↑ 400.0%**  | **↑ 725.0%** | **↑ 147.83%**  | **↑ 68.42%**  | **↑ 125.0%**  | **↑ 151.85%**  | **↑ 200.0%**  | **↑ 185.71%**  | **↑ 77.06%**   | **↑ 176.47%** | **↑ 175.0%**      | **↑ 183.33%** | **↑ 161.54%** |
| RT-DETR-L [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/RT-DETRv1/FI_rtder-l.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-RT/GOIS_rtdetr-l.json) | 0.11 / 0.22    | 0.44 / 1.03  | 0.67 / 0.95    | 1.34 / 1.49    | 0.32 / 0.46 | 0.81 / 1.16   | 1.01 / 1.71   | 1.44 / 2.25     | 2.45 / 2.73     | 0.61 / 0.90  | 0.43 / 0.61        | 0.67 / 0.94   | 0.44 / 0.63   |
|                                                                                               | **↑ 100.0%**  | **↑ 134.09%**| **↑ 41.79%**   | **↑ 11.19%**  | **↑ 43.75%**  | **↑ 43.21%**   | **↑ 69.31%**  | **↑ 56.25%**   | **↑ 11.43%**   | **↑ 47.54%**  | **↑ 41.86%**      | **↑ 40.3%**   | **↑ 43.18%**  |
| YOLOv10 [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/yolov10-v1/FI_yolov10n.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-Yolo10/GOIS_yolov10n.json) | 0.02 / 0.08    | 0.02 / 0.27  | 0.18 / 0.56    | 0.63 / 0.93    | 0.13 / 0.26 | 0.25 / 0.61   | 0.27 / 0.76   | 0.38 / 1.25     | 1.18 / 1.85     | 0.17 / 0.44  | 0.12 / 0.31        | 0.17 / 0.48   | 0.13 / 0.33   |
|                                                                                               | **↑ 300.0%**  | **↑ 1250.0%**| **↑ 211.11%**  | **↑ 47.62%**  | **↑ 100.0%**  | **↑ 144.0%**   | **↑ 181.48%** | **↑ 228.95%**  | **↑ 56.78%**   | **↑ 158.82%** | **↑ 158.33%**     | **↑ 182.35%** | **↑ 153.85%** |
| YOLOv9 [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/Yolov9-v1/FI_YOLOv9c.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-YOLO9/GOIS_YOLOv9c.json) | 0.06 / 0.18    | 0.17 / 0.53  | 0.72 / 0.90    | 1.33 / 1.18    | 0.30 / 0.40 | 0.65 / 0.91   | 0.73 / 1.16   | 1.20 / 1.79     | 2.22 / 2.21     | 0.52 / 0.73  | 0.41 / 0.53        | 0.56 / 0.76   | 0.45 / 0.58   |
|                                                                                               | **↑ 200.0%**  | **↑ 211.76%**| **↑ 25.0%**    | **↓ 11.28%** | **↑ 33.33%**  | **↑ 40.0%**    | **↑ 58.9%**   | **↑ 49.17%**   | **↓ 0.45%**   | **↑ 40.38%**  | **↑ 29.27%**      | **↑ 35.71%**  | **↑ 28.89%**  |
| YOLOv8n [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/Yolov8-v1/FI_yolov8n.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-YOLO8/GOIS_yolov8n.json) | 0.03 / 0.13    | 0.04 / 0.39  | 0.24 / 0.53    | 0.54 / 0.97    | 0.15 / 0.28 | 0.29 / 0.67   | 0.32 / 0.84   | 0.50 / 1.34     | 1.22 / 1.93     | 0.19 / 0.44  | 0.14 / 0.30        | 0.20 / 0.47   | 0.14 / 0.32   |
|                                                                                               | **↑ 333.33%** | **↑ 875.0%** | **↑ 120.83%**  | **↑ 79.63%** | **↑ 86.67%**  | **↑ 131.03%**  | **↑ 162.5%**  | **↑ 168.0%**   | **↑ 58.2%**   | **↑ 131.58%** | **↑ 114.29%**     | **↑ 135.0%**  | **↑ 128.57%** |
| YOLOv5n [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/Yolov5-v1/FI_yolov5su.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-YOLO5/GOIS_yolov5su.json) | 0.03 / 0.16    | 0.10 / 0.51  | 0.32 / 0.65    | 0.79 / 1.02    | 0.16 / 0.29 | 0.36 / 0.71   | 0.41 / 0.93   | 0.67 / 1.44     | 1.51 / 1.93     | 0.25 / 0.54  | 0.18 / 0.38        | 0.27 / 0.58   | 0.19 / 0.41   |
|                                                                                               | **↑ 433.33%** | **↑ 410.0%** | **↑ 103.12%**  | **↑ 29.11%** | **↑ 81.25%**  | **↑ 97.22%**   | **↑ 126.83%** | **↑ 114.93%**  | **↑ 27.81%**  | **↑ 116.0%**  | **↑ 111.11%**     | **↑ 114.81%** | **↑ 115.79%** |
| YOLOv8s-WorldV2 [FI-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/yolo8world-v1/FI_yolov8s-worldv2.json), [GOIS-Det](https://github.com/MMUZAMMUL/Small-Object-Detection-Benchmarks-Full_ImageVsGOIS/releases/download/GOIS-YOLOWORLD/GOIS_yolov8s-worldv2.json) | 0.04 / 0.16    | 0.11 / 0.48  | 0.42 / 0.68    | 0.90 / 1.01    | 0.21 / 0.36 | 0.42 / 0.84   | 0.46 / 1.03   | 0.75 / 1.59     | 1.79 / 1.97     | 0.30 / 0.58  | 0.23 / 0.40        | 0.34 / 0.60   | 0.23 / 0.43   |
|                                                                                               | **↑ 300.0%**  | **↑ 336.36%**| **↑ 61.9%**    | **↑ 12.22%** | **↑ 71.43%**  | **↑ 100.0%**   | **↑ 123.91%** | **↑ 112.0%**   | **↑ 10.06%**  | **↑ 93.33%**  | **↑ 73.91%**      | **↑ 76.47%**  | **↑ 86.96%**  |


# Section 2: Fine Tuning Models with 10 epoches Visdrone Traning and then Inference results  on  Full Dataset(6,471 Images) VisDrone2019Train 

## Comparative Results for FI-Det and GOIS-Det
This table presents the Average Precision (AP) and Average Recall (AR) metrics for five models (YOLO11, YOLOv10, YOLOv9, YOLOv8, YOLOv5). Each model includes three rows: FI-Det results, GOIS-Det results, and % improvement achieved by GOIS. Downloadable links for FI-Det and GOIS-Det results are included in the first column next to the model name. Ground Truth COCO for this evaluation available at | [FullTraineDatasetGT](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/Full-VisdroneTrain-COCO-GT/ground_truth_coco.json)

| **Model**                                                                                      | **AP-Small** | **AR-Small** | **AP-Medium** | **AP-Large** | **AR@1** | **AR@10** | **AR@100** | **AR-Medium** | **AR-Large** | **F1 Score** | **AP@[IoU=0.50:0.95]** | **AP@[IoU=0.50]** | **AP@[IoU=0.75]** |
|------------------------------------------------------------------------------------------------|--------------|--------------|---------------|--------------|----------|-----------|------------|---------------|--------------|--------------|------------------------|-------------------|-------------------|
| YOLO11 [FI-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv11-FI/Yolo11n_predictions_coco.json), [GOIS-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv11-GOIS/Yolo11n-gois_predictions_coco.json) | 0.024        | 0.035        | 0.159         | 0.283        | 0.045    | 0.112     | 0.137      | 0.208         | 0.349        | 0.17         | 0.12                   | 0.171             | 0.119             |
| **%age↑↓**                                                                                   | **↑ 196.90%**| **↑ 278.66%**| **↑ 2.94%**   | **↓ 46.71%** | **↑ 18.81%**| **↑ 35.46%**| **↑ 51.17%** | **↑ 31.44%**  | **↓ 34.90%** | **↑ 176.47%**| **↑ 12.01%**          | **↑ 12.38%**      | **↑ 11.26%**      |
| YOLOv10 [FI-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv10-FI/Yolo10-full_predictions_coco.json), [GOIS-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv10-GOIS/Yolo10-gois_predictions_coco.json) | 0.022        | 0.029        | 0.133         | 0.222        | 0.041    | 0.097     | 0.117      | 0.178         | 0.278        | 0.17         | 0.091                  | 0.140             | 0.100             |
| **%age↑↓**                                                                                   | **↑ 176.54%**| **↑ 279.22%**| **↓ 2.30%**   | **↓ 54.85%** | **↑ 14.18%**| **↑ 31.01%**| **↑ 46.09%** | **↑ 22.50%**  | **↓ 42.82%** | **↑ 158.82%**| **↑ 8.88%**           | **↑ 11.40%**      | **↑ 7.08%**       |
| YOLOv9 [FI-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv9-FI/Yolo9-full_predictions_coco.json), [GOIS-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv9-GOIS/Yolo9-gois_predictions_coco.json) | 0.079        | 0.103        | 0.320         | 0.472        | 0.080    | 0.211     | 0.252      | 0.387         | 0.551        | 0.17         | 0.212                  | 0.322             | 0.232             |
| **%age↑↓**                                                                                   | **↑ 64.98%** | **↑ 127.93%**| **↓ 24.20%**  | **↓ 63.83%** | **↓ 1.07%**| **↑ 9.85%**| **↑ 22.94%**| **↑ 2.38%**   | **↓ 56.64%** | **↑ 158.82%**| **↓ 11.93%**          | **↓ 8.15%**       | **↓ 14.10%**      |
| YOLOv8 [FI-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv8-FI/Yolo8-full_predictions_coco.json), [GOIS-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-YOLOv8-GOIS/Yolo8-gois_predictions_coco.json) | 0.025        | 0.032        | 0.158         | 0.290        | 0.046    | 0.113     | 0.136      | 0.209         | 0.365        | 0.17         | 0.108                  | 0.168             | 0.118             |
| **%age↑↓**                                                                                   | **↑ 178.14%**| **↑ 308.02%**| **↑ 3.22%**   | **↓ 48.67%** | **↑ 22.33%**| **↑ 40.05%**| **↑ 55.92%** | **↑ 34.65%**  | **↓ 39.72%** | **↑ 176.47%**| **↑ 11.82%**          | **↑ 14.46%**      | **↑ 10.03%**      |
| YOLOv5 [FI-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-Yolov5-FI/Yolo5-full_predictions_coco.json), [GOIS-Det](https://github.com/MMUZAMMUL/TinyObjectDetectionGOIS-Benchmarks/releases/download/FT-Yolov5-GOIS/Yolo5-gois_predictions_coco.json) | 0.019        | 0.026        | 0.138         | 0.270        | 0.040    | 0.098     | 0.119      | 0.178         | 0.278        | 0.17         | 0.096                  | 0.150             | 0.104             |
| **%age↑↓**                                                                                   | **↑ 209.43%**| **↑ 329.90%**| **↑ 9.07%**   | **↓ 50.16%** | **↑ 26.22%**| **↑ 42.71%**| **↑ 58.12%** | **↑ 40.05%**  | **↓ 37.62%** | **↑ 216.47%**| **↑ 13.61%**          | **↑ 16.09%**      | **↑ 11.36%**      |



**Notes:**
- ↑ represents percentage improvement achieved by GOIS-Det over FI-Det.
- ↓ represents performance degradation in GOIS-Det compared to FI-Det.

